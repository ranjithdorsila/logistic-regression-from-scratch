{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "raw",
      "source": "4. Experimenting with regularization and Cost function",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#importing the packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math\nimport sys\nfrom sklearn.metrics import confusion_matrix",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#reading the dataset\ns = 'flu_data.csv'\ndf = pd.read_csv(s)\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Student  Vaccin  HndWshQual  HndWshFreq  SociDist  NoFaceContact  \\\n0        1       3           4           4         2              1   \n1        2       2           4           4         5              2   \n2        3       3           2           2         2              3   \n3        4       3           3           2         2              2   \n4        5       2           5           3         3              2   \n\n   RespEttiqu  PersnDist  HandSanit   Risk  Complications  Barriers  \\\n0           5          1          1 -0.770         -1.453     0.000   \n1           5          4          4 -0.345          0.000    -0.489   \n2           2          2          1 -0.406         -0.575    -0.234   \n3           5          3          1 -0.575         -0.197    -0.429   \n4           5          5          3  0.000         -0.770     0.097   \n\n   Inefficacy  KnowlTrans  KnowlMgmt  Sick  Flu  Female  \n0       0.929      -0.554      0.000   0.0  0.0     1.0  \n1       0.149      -0.554      1.482   1.0  0.0     0.0  \n2       0.693      -0.182     -1.482   0.0  0.0     0.0  \n3       0.000       0.554      0.000   2.0  1.0     NaN  \n4       0.546       0.554      0.684   1.0  0.0     0.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Student</th>\n      <th>Vaccin</th>\n      <th>HndWshQual</th>\n      <th>HndWshFreq</th>\n      <th>SociDist</th>\n      <th>NoFaceContact</th>\n      <th>RespEttiqu</th>\n      <th>PersnDist</th>\n      <th>HandSanit</th>\n      <th>Risk</th>\n      <th>Complications</th>\n      <th>Barriers</th>\n      <th>Inefficacy</th>\n      <th>KnowlTrans</th>\n      <th>KnowlMgmt</th>\n      <th>Sick</th>\n      <th>Flu</th>\n      <th>Female</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.770</td>\n      <td>-1.453</td>\n      <td>0.000</td>\n      <td>0.929</td>\n      <td>-0.554</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>-0.345</td>\n      <td>0.000</td>\n      <td>-0.489</td>\n      <td>0.149</td>\n      <td>-0.554</td>\n      <td>1.482</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>-0.406</td>\n      <td>-0.575</td>\n      <td>-0.234</td>\n      <td>0.693</td>\n      <td>-0.182</td>\n      <td>-1.482</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>3</td>\n      <td>1</td>\n      <td>-0.575</td>\n      <td>-0.197</td>\n      <td>-0.429</td>\n      <td>0.000</td>\n      <td>0.554</td>\n      <td>0.000</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>3</td>\n      <td>0.000</td>\n      <td>-0.770</td>\n      <td>0.097</td>\n      <td>0.546</td>\n      <td>0.554</td>\n      <td>0.684</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "raw",
      "source": "a) Regularization and Feature Scaling:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#coding the sigmoid function\ndef sigmoid(x,parameters):\n    hx=np.dot(x,parameters)\n    return 1/(1+np.exp(-hx))\n#coding the cost function\ndef costfun(x,y,parameters,m,sigmod):\n    y=np.array(y)\n    return (-1/m)*np.sum((y*np.log(sigmod))+(1-y)*np.log(1-sigmod))\n#coding the logistic regression from scratch\ndef logisticregression(x,y,lr,parameters,iters,m,lambd):\n    costfunctionvalues=[]\n    for i in range(iters):\n        sigmod=sigmoid(x,parameters)\n        #added the regularization to the below function\n        gradient = (np.dot(x.T,(sigmod - np.array([y]))))+(lambd*np.sum(parameters)) / m\n        parameters=parameters-(lr*gradient).T\n        parameters=parameters[0][0]\n        costfunctionvalues.append(costfun(x,y,parameters,m,sigmod))\n    return parameters\n#predicton function for calculating predicted values\ndef prediction(x,parameters,cuttingvalue):\n    value=sigmoid(x,parameters)\n    if (value > cuttingvalue) :\n        return 1\n    else:\n        return 0\n#calculating the  performance metrics   \ndef performance(gh,y,d1,parameters,s):\n    predicted=[]\n    for i in range(s):\n        predicted.append(prediction(gh.iloc[[i]],parameters,0.7))       \n    yc=d1['Flu']  \n    print(\"confusion matrix\")\n    print(confusion_matrix(y,predicted) )\n    tp=0\n    fp=0\n    fn=0\n    tn=0\n    for i in range(s):\n        if(yc[i]==1 and predicted[i]==1):\n            tp=tp+1\n        \n        if(yc[i]==0 and predicted[i]==1):\n            fp=fp+1\n        \n        if(yc[i]==1 and predicted[i]==0):\n            fn=fn+1\n        \n        if(yc[i]==0 and predicted[i]==0):\n            tn=tn+1    \n    print(\"accuracy\")\n    if((tp+tn+fp+fn)== 0):\n        print(\"0\")\n    else:    \n        print((tp+tn)/(tp+tn+fp+fn))\n    print(\"precision\")    \n    if((tp+fp)==0): \n        print(\"0\")\n    else:    \n        print((tp)/(tp+fp))\n    print(\"recall\")    \n    if((tp+fn)==0):\n        print(\"0\")\n    else:    \n        print((tp)/(tp+fn))  ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "source": "I. For the best performing model in Q 3 (Model from 3c), does regularization improve \nthe performance?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "key1=['Risk','HndWshQual','HndWshFreq','Flu']\nd1=pd.DataFrame(df[key1])\nd1.isnull().sum()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Risk           0\nHndWshQual     0\nHndWshFreq     0\nFlu           36\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "d1['Flu'].fillna(value=0.0,inplace=True)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#features that got best accuracy in 3c\nx=d1[['Risk','HndWshQual','HndWshFreq']]\ny=d1[['Flu']]\ns=x.shape[0] \nm=x.shape[1]\nlr=0.1\nparameters=np.ones(m)\niters=100\nlambd=0.63\nparameters=logisticregression(x,y,lr,parameters,iters,s,lambd)\nperformance(x,y,d1,parameters,s)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "text": "confusion matrix\n[[327   5]\n [ 72   6]]\naccuracy\n0.8121951219512196\nprecision\n0.5454545454545454\nrecall\n0.07692307692307693\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "raw",
      "source": "II. Does Feature Scaling improve the performance for the model in Q 4a?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#feature scaling by minmax scaling\nmx=np.max(x)\nmi=np.min(x)\nxs=(x-mi)/(mx-mi)\nparameters=np.ones(m)\nparameters=logisticregression(xs,y,lr,parameters,iters,s,lambd)\nperformance(xs,y,d1,parameters,s)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "text": "confusion matrix\n[[ 53 279]\n [  0  78]]\naccuracy\n0.3195121951219512\nprecision\n0.2184873949579832\nrecall\n1.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "raw",
      "source": "No, Feature Scaling doe not improve the performance for the model in Q 4a.",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "b) Cost Function:",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "I. Keeping the best regularized (or not) model after the experiments from 4a, design \na Logistic Regression model to predict whether a student reported flu-like\nsymptoms in the past year i.e., Flu(y) by changing the cost function to the \nfollowing.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#sigmoid function\ndef sigmoid(x,parameters):\n    hx=np.dot(x,parameters)\n    return 1/(1+np.exp(-hx))\n#cost function is changed\ndef costfun(x,y,parameters,m,sigmod):\n    y=np.array(y)\n    return (-1/(2*m))*np.sum((sigmod-y)*(sigmod-y))\n#coding the logistic regression from scratch\ndef logisticregression(x,y,lr,parameters,iters,m,lambd):\n    costfunctionvalues=[]\n    for i in range(iters):\n        sigmod=sigmoid(x,parameters)\n        #added the regularization to the below function\n        gradient = (np.dot(x.T,(sigmod - np.array([y]))))+(lambd*np.sum(parameters)) / m\n        parameters=parameters-(lr*gradient).T\n        parameters=parameters[0][0]\n        costfunctionvalues.append(costfun(x,y,parameters,m,sigmod))    \n    return parameters\n#predicton function for calculating predicted values\ndef prediction(x,parameters,cuttingvalue):\n    value=sigmoid(x,parameters)\n    if (value > cuttingvalue) :\n        return 1\n    else:\n        return 0\n#calculating the  performance metrics   \ndef performance(gh,y,d1,parameters,s):\n    predicted=[]\n    for i in range(s):\n        predicted.append(prediction(gh.iloc[[i]],parameters,0.7))       \n    yc=d1['Flu']  \n    print(\"confusion matrix\")\n    print(confusion_matrix(y,predicted) )\n    tp=0\n    fp=0\n    fn=0\n    tn=0\n    for i in range(s):\n        if(yc[i]==1 and predicted[i]==1):\n            tp=tp+1\n        \n        if(yc[i]==0 and predicted[i]==1):\n            fp=fp+1\n        \n        if(yc[i]==1 and predicted[i]==0):\n            fn=fn+1\n        \n        if(yc[i]==0 and predicted[i]==0):\n            tn=tn+1    \n    print(\"accuracy\")\n    if((tp+tn+fp+fn)== 0):\n        print(\"0\")\n    else:    \n        print((tp+tn)/(tp+tn+fp+fn))\n    print(\"precision\")    \n    if((tp+fp)==0): \n        print(\"0\")\n    else:    \n        print((tp)/(tp+fp))\n    print(\"recall\")    \n    if((tp+fn)==0):\n        print(\"0\")\n    else:    \n        print((tp)/(tp+fn))  ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "parameters=np.ones(m)\nparameters=logisticregression(x,y,lr,parameters,iters,s,lambd)\nperformance(x,y,d1,parameters,s)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "text": "confusion matrix\n[[327   5]\n [ 72   6]]\naccuracy\n0.8121951219512196\nprecision\n0.5454545454545454\nrecall\n0.07692307692307693\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "raw",
      "source": "II. Compare the performance of both the models (4.b.i and 4.a.). Do they give the \nsame solution with a difference in cost function?",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "yes 4a and 4bi gave the same accuracies 0.812 and 0.812 even after cost function is changed.",
      "metadata": {}
    }
  ]
}